---
title: About Narratives in the Wild
layout: page
description: Research project focused on collaborative narrative annotation for understanding misinformation in social media ecosystems.
bodyClass: page-about
---

The modern social media ecosystem is in crisis. Recent events have created a stranglehold over most social media, with the purchase of Twitter by Elon Musk, TikTok's internal censorship and threatened U.S. ban, moderation changes at Meta, and the closing of research APIs supporting an online information ecosystem where misinformation and disinformation can thrive.

# Our Approach

Battling to correct individual pieces of misinformation is perhaps always a losing game. As Alice Marwick, director of Data & Society, notes: "The problem is less about 'units of facts'... The problem is with these big, sticky stories."

Narratives in the Wild addresses this challenge by focusing on the underlying narrative patterns that spread across communities, rather than fact-checking individual posts.

## Key Research Goals

1. **Build collaborative narrative labeling pipeline** on Bluesky using moderation services
2. **Enable multi-stakeholder annotation** by researchers, community members, and users
3. **Create open datasets** for narrative research across disciplines
4. **Address misinformation through narrative understanding** rather than individual fact-checking

## Why Bluesky?

Bluesky is a new social media platform built using the AT Protocol, a decentralized protocol for large-scale social web applications. Bluesky's open and "hackable" structure makes it ideal for computational social experiments.

Bluesky labels can be designed and applied by any user who chooses to run a moderation service. Other users may then subscribe to any of these services, which can hide, warn, or simply display a label for relevant contentâ€”all opt-in.

## Our Methodology

Our working prototype uses the open-source Ozone library to provide a usable interface:

1. **Research teams propose** topic-specific narrative annotation tasks through a formal process
2. **Community members flag posts** and provide rationales and labels
3. **Trusted annotators** iteratively cluster and assign labels in moderation queues
4. **Open datasets** are immediately available via downloadable datasets and personalized dashboards

## Impact

This project creates a new approach to combating harmful online content by focusing on "big, sticky stories" rather than individual fact-checking. We enable researchers to connect individual units of information into coherent narratives, going beyond narrow factuality to characterize online content holistically.

## Funding

The research team is supported by the Pioneer Centre for AI, DNRF grant number P1. This work is further supported by the European Union (ERC, ExplainYourself, 101077481, a DFF Sapere Aude research leader grant under grant agreement No 0171-00034B, and a Danish Data Science Academy postdoctoral fellowship (grant: 2023-1425). Views and opinions expressed are those of the researchers only and do not necessarily reflect those of the European Union or the European Research Council. Neither the European Union nor the granting authority can be held responsible for them.
