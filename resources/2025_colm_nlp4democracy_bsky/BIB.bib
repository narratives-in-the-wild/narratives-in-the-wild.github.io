@inproceedings{piper-etal-2021-narrative,
    title = {{Narrative Theory for Computational Narrative Understanding}},
    author = "Piper, Andrew  and
      So, Richard Jean  and
      Bamman, David",
    NOeditor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "EMNLP 2021",
    month = nov,
    year = "2021",
    NOaddress = "Online and Punta Cana, Dominican Republic",
    NOpublisher = "ACL",
    url = "https://aclanthology.org/2021.emnlp-main.26/",
    NOpages = "298--311",
    abstract = "Over the past decade, the field of natural language processing has developed a wide array of computational methods for reasoning about narrative, including summarization, commonsense inference, and event detection. While this work has brought an important empirical lens for examining narrative, it is by and large divorced from the large body of theoretical work on narrative within the humanities, social and cognitive sciences. In this position paper, we introduce the dominant theoretical frameworks to the NLP community, situate current research in NLP within distinct narratological traditions, and argue that linking computational work in NLP to theory opens up a range of new empirical questions that would both help advance our understanding of narrative and open up new practical applications."
}

@inproceedings{antoniak-etal-2024-people,
    title = {{Where Do People Tell Stories Online? {S}tory Detection Across Online Communities}},
    author = "Antoniak, Maria  and
      Mire, Joel  and
      Sap, Maarten  and
      Ash, Elliott  and
      Piper, Andrew",
    NOeditor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "ACL",
    month = aug,
    year = "2024",
    NOaddress = "Bangkok, Thailand",
    NOpublisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.luhme-long.383/",
    NOpages = "7104--7130",
    abstract = "Story detection in online communities is a challenging task as stories are scattered across communities and interwoven with non-storytelling spans within a single text. We address this challenge by building and releasing the StorySeeker toolkit, including a richly annotated dataset of 502 Reddit posts and comments, a detailed codebook adapted to the social media context, and models to predict storytelling at the document and span levels. Our dataset is sampled from hundreds of popular English-language Reddit communities ranging across 33 topic categories, and it contains fine-grained expert annotations, including binary story labels, story spans, and event spans. We evaluate a range of detection methods using our data, and we identify the distinctive textual features of online storytelling, focusing on storytelling spans, which we introduce as a new task. We illuminate distributional characteristics of storytelling on a large community-centric social media platform, and we also conduct a case study on r/ChangeMyView, where storytelling is used as one of many persuasive strategies, illustrating that our data and models can be used for both inter- and intra-community research. Finally, we discuss implications of our tools and analyses for narratology and the study of online communities."
}


@misc{starbird2024facts,
  title={{Facts, frames, and (mis)interpretations: Understanding rumors as collective sensemaking}},
  author={Starbird, K},
  URL={https://www.cip.uw.edu/2023/12/06/rumors-collective-sensemaking-kate-starbird/},
  year={2024}
}

@misc{christensen2022searchingstructureunfalsifiableclaims,
      title={{Searching for Structure in Unfalsifiable Claims}}, 
      author={Peter Ebert Christensen and Frederik Warburg and Menglin Jia and Serge Belongie},
      year={2022},
      eprint={2209.00495},
      archivePrefix={arXiv},
      NOprimaryClass={cs.CL},
      NOurl={https://arxiv.org/abs/2209.00495}, 
}

@article{tangherlini2020automated,
  title={An automated pipeline for the discovery of conspiracy and conspiracy theory narrative frameworks: Bridgegate, Pizzagate and storytelling on the web},
  author={Tangherlini, Timothy R and Shahsavari, Shadi and Shahbazi, Behnam and Ebrahimzadeh, Ehsan and Roychowdhury, Vwani},
  journal={PloS one},
  NOvolume={15},
  NOnumber={6},
  NOpages={e0233879},
  year={2020},
  NOpublisher={Public Library of Science San Francisco, CA USA}
}


@article{shahsavari2020conspiracy,
  title={{Conspiracy in the time of corona: automatic detection of emerging COVID-19 conspiracy theories in social media and the news}},
  author={Shahsavari, Shadi and Holur, Pavan and Wang, Tianyi and Tangherlini, Timothy R and Roychowdhury, Vwani},
  journal={Journal of computational social science},
  NOvolume={3},
  NOnumber={2},
  NOpages={279--317},
  year={2020},
  publisher={Springer}
}

@misc{vanderwa2007folksonomy,
  title={Folksonomy},
  author={Vander Wal, Thomas},
  year={2005},
  howpublished = "Presented at Online Information, London, UK",
  url={https://www.vanderwal.net/essays/051130/folksonomy.pdf}}

@inproceedings{bamman-etal-2020-annotated,
    title = "An Annotated Dataset of Coreference in {E}nglish Literature",
    author = "Bamman, David  and
      Lewke, Olivia  and
      Mansoor, Anya",
    NOeditor = "Calzolari, Nicoletta  and
      B{\'e}chet, Fr{\'e}d{\'e}ric  and
      Blache, Philippe  and
      Choukri, Khalid  and
      Cieri, Christopher  and
      Declerck, Thierry  and
      Goggi, Sara  and
      Isahara, Hitoshi  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Mazo, H{\'e}l{\`e}ne  and
      Moreno, Asuncion  and
      Odijk, Jan  and
      Piperidis, Stelios",
    booktitle = "LREC",
    month = may,
    year = "2020",
    NOaddress = "Marseille, France",
    NOpublisher = "European Language Resources Association",
    url = "https://aclanthology.org/2020.lrec-1.6/",
    NOpages = "44--54",
    NOlanguage = "eng",
    NOISBN = "979-10-95546-34-4",
    abstract = "We present in this work a new dataset of coreference annotations for works of literature in English, covering 29,103 mentions in 210,532 tokens from 100 works of fiction published between 1719 and 1922. This dataset differs from previous coreference corpora in containing documents whose average length (2,105.3 words) is four times longer than other benchmark datasets (463.7 for OntoNotes), and contains examples of difficult coreference problems common in literature. This dataset allows for an evaluation of cross-domain performance for the task of coreference resolution, and analysis into the characteristics of long-distance within-document coreference."
}


@inproceedings{sims-etal-2019-literary,
    title = "Literary Event Detection",
    author = "Sims, Matthew  and
      Park, Jong Ho  and
      Bamman, David",
    NOeditor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'i}s",
    booktitle = "ACL",
    month = jul,
    year = "2019",
    NOaddress = "Florence, Italy",
    NOpublisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P19-1353/",
    NOpages = "3623--3634",
    abstract = "In this work we present a new dataset of literary events{---}events that are depicted as taking place within the imagined space of a novel. While previous work has focused on event detection in the domain of contemporary news, literature poses a number of complications for existing systems, including complex narration, the depiction of a broad array of mental states, and a strong emphasis on figurative language. We outline the annotation decisions of this new dataset and compare several models for predicting events; the best performing model, a bidirectional LSTM with BERT token representations, achieves an F1 score of 73.9. We then apply this model to a corpus of novels split across two dimensions{---}prestige and popularity{---}and demonstrate that there are statistically significant differences in the distribution of events for prestige."
}


@inproceedings{bamman-etal-2019-annotated,
    title = "An annotated dataset of literary entities",
    author = "Bamman, David  and
      Popat, Sejal  and
      Shen, Sheng",
    NOeditor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "NAACL",
    month = jun,
    year = "2019",
    NOaddress = "Minneapolis, Minnesota",
    NOpublisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1220/",
    NOpages = "2138--2144",
    abstract = "We present a new dataset comprised of 210,532 tokens evenly drawn from 100 different English-language literary texts annotated for ACE entity categories (person, location, geo-political entity, facility, organization, and vehicle). These categories include non-named entities (such as {\textquotedblleft}the boy{\textquotedblright}, {\textquotedblleft}the kitchen{\textquotedblright}) and nested structure (such as [[the cook]`s sister]). In contrast to existing datasets built primarily on news (focused on geo-political entities and organizations), literary texts offer strikingly different distributions of entity categories, with much stronger emphasis on people and description of settings. We present empirical results demonstrating the performance of nested entity recognition models in this domain; training natively on in-domain literary data yields an improvement of over 20 absolute points in F-score (from 45.7 to 68.3), and mitigates a disparate impact in performance for male and female entities present in models trained on news data."
}




@article{abello2012computational,
author = {Abello, James and Broadwell, Peter and Tangherlini, Timothy R.},
title = {Computational folkloristics},
year = {2012},
NOissue_date = {July 2012},
publisher = {ACM Communications},
NOaddress = {New York, NY, USA},
NOvolume = {55},
NOnumber = {7},
NOissn = {0001-0782},
url = {https://doi.org/10.1145/2209249.2209267},
abstract = {A searchable meta-graph can connect even troublesome house elves and other supernatural beings to scholarly folk categories.},
NOjournal = {Commun. ACM},
month = jul,
NOpages = {60–70},
NOnumpages = {11}
}

@proceedings{wnu-2024-1,
    title = "Proceedings of the The 6th Workshop on Narrative Understanding",
    editor = "Lal, Yash Kumar  and
      Clark, Elizabeth  and
      Iyyer, Mohit  and
      Chaturvedi, Snigdha  and
      Brei, Anneliese  and
      Brahman, Faeze  and
      Chandu, Khyathi Raghavi",
    month = nov,
    year = "2024",
    NOaddress = "Miami, Florida, USA",
    publisher = "ACL",
    url = "https://aclanthology.org/2024.wnu-1.0/",
}

@inproceedings{shokri-etal-2024-safe,
    title = {{Is It Safe to Tell Your Story? {T}owards Achieving Privacy for Sensitive Narratives}},
    author = "Shokri, Mohammad  and
      Bishop, Allison  and
      Levitan, Sarah Ita",
    NOeditor = "Lal, Yash Kumar  and
      Clark, Elizabeth  and
      Iyyer, Mohit  and
      Chaturvedi, Snigdha  and
      Brei, Anneliese  and
      Brahman, Faeze  and
      Chandu, Khyathi Raghavi",
    booktitle = "Proceedings of the 6th Workshop on Narrative Understanding",
    month = nov,
    year = "2024",
    NOaddress = "Miami, Florida, USA",
    publisher = "ACL",
    Nourl = "https://aclanthology.org/2024.wnu-1.7/",
    NOpages = "47--54",
    abstract = "Evolving tools for narrative analysis present an opportunity to identify common structure in stories that are socially important to tell, such as stories of survival from domestic abuse. A greater structural understanding of such stories could lead to stronger protections against de-anonymization, as well as future tools to help survivors navigate the complex trade-offs inherent in trying to tell their stories safely. In this work we explore narrative patterns within a small set of domestic violence stories, identifying many similarities. We then propose a method to assess the safety of sharing a story based on a distance feature vector."
}

@inproceedings{baly-etal-2018-predicting,
    title = {{Predicting Factuality of Reporting and Bias of News Media Sources}},
    author = "Baly, Ramy  and
      Karadzhov, Georgi  and
      Alexandrov, Dimitar  and
      Glass, James  and
      Nakov, Preslav",
    NOeditor = "Riloff, Ellen  and
      Chiang, David  and
      Hockenmaier, Julia  and
      Tsujii, Jun{'}ichi",
    booktitle = "Proceedings of EMNLP",
    NOmonth = oct # "-" # nov,
    year = "2018",
    NOaddress = "Brussels, Belgium",
    NOpublisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D18-1389/",
    NOpages = "3528--3539",
    abstract = "We present a study on predicting the factuality of reporting and bias of news media. While previous work has focused on studying the veracity of claims or documents, here we are interested in characterizing entire news media. This is an under-studied, but arguably important research problem, both in its own right and as a prior for fact-checking systems. We experiment with a large list of news websites and with a rich set of features derived from (i) a sample of articles from the target news media, (ii) its Wikipedia page, (iii) its Twitter account, (iv) the structure of its URL, and (v) information about the Web traffic it attracts. The experimental results show sizable performance gains over the baseline, and reveal the importance of each feature type."
}

@inproceedings{piper-etal-2024-social,
    title = "The Social Lives of Literary Characters: Combining citizen science and language models to understand narrative social networks",
    author = "Piper, Andrew  and
      Xu, Michael  and
      Ruths, Derek",
    NOeditor = {H{\"a}m{\"a}l{\"a}inen, Mika  and
      {\"O}hman, Emily  and
      Miyagawa, So  and
      Alnajjar, Khalid  and
      Bizzoni, Yuri},
    booktitle = "Proceedings of the 4th International Conference on Natural Language Processing for Digital Humanities",
    month = nov,
    year = "2024",
    address = "Miami, USA",
    publisher = "ACL",
    url = "https://aclanthology.org/2024.nlp4dh-1.45/",
    NOpages = "472--482",
    abstract = "Characters and their interactions are central to the fabric of narratives, playing a crucial role in developing readers' social cognition. In this paper, we introduce a novel annotation framework that distinguishes between five types of character interactions, including bilateral and unilateral classifications. Leveraging the crowd-sourcing framework of citizen science, we collect a large dataset of manual annotations (N=13,395). Using this data, we explore how genre and audience factors influence social network structures in a sample of contemporary books. Our findings demonstrate that fictional narratives tend to favor more embodied interactions and exhibit denser and less modular social networks. Our work not only enhances the understanding of narrative social networks but also showcases the potential of integrating citizen science with NLP methodologies for large-scale narrative analysis."
}

@article{10.14778/2777598.2777603,
author = {Dong, Xin Luna and Gabrilovich, Evgeniy and Murphy, Kevin and Dang, Van and Horn, Wilko and Lugaresi, Camillo and Sun, Shaohua and Zhang, Wei},
title = {{Knowledge-Based Trust: Estimating the Trustworthiness of Web Sources}},
year = {2015},
NOissue_date = {May 2015},
NOpublisher = {VLDB Endowment},
NOvolume = {8},
NOnumber = {9},
NOissn = {2150-8097},
url = {https://doi.org/10.14778/2777598.2777603},
abstract = {The quality of web sources has been traditionally evaluated using exogenous signals such as the hyperlink structure of the graph. We propose a new approach that relies on endogenous signals, namely, the correctness of factual information provided by the source. A source that has few false facts is considered to be trustworthy.The facts are automatically extracted from each source by information extraction methods commonly used to construct knowledge bases. We propose a way to distinguish errors made in the extraction process from factual errors in the web source per se, by using joint inference in a novel multi-layer probabilistic model.We call the trustworthiness score we computed Knowledge-Based Trust (KBT). On synthetic data, we show that our method can reliably compute the true trustworthiness levels of the sources. We then apply it to a database of 2.8B facts extracted from the web, and thereby estimate the trustworthiness of 119M webpages. Manual evaluation of a subset of the results confirms the effectiveness of the method.},
journal = {Proceedings VLDB Endowment},
month = may,
NOpages = {938–949},
NOnumpages = {12}
}

@book{smith2007tagging,
  title={{Tagging: People-Powered Metadata for the Social Web, Safari}},
  author={Smith, Gene},
  year={2007},
  publisher={New Riders}
}



@article{antoniak2021tags,
author = {Antoniak, Maria and Walsh, Melanie and Mimno, David},
title = {Tags, Borders, and Catalogs: Social Re-Working of Genre on LibraryThing},
year = {2021},
NOissue_date = {April 2021},
publisher = {ACM},
NOaddress = {New York, NY, USA},
NOvolume = {5},
NOnumber = {CSCW1},
url = {https://doi.org/10.1145/3449103},
abstract = {Through a computational reading of the online book reviewing community LibraryThing, we examine the dynamics of a collaborative tagging system and learn how its users refine and redefine literary genres. LibraryThing tags are overlapping and multi-dimensional, created in a shared space by thousands of users, including readers, bookstore owners, and librarians. A common understanding of genre is that it relates to the content of books, but this resource allows us to view genre as an intersection of user communities and reader values and interests. We explore different methods of computational genre measurement within the open space of user-created tags. We measure overlap between books, tags, and users, and we also measure the homogeneity of communities associated with genre tags and correlate this homogeneity with reviewing behavior.Finally, by analyzing the text of reviews, we identify the thematic signatures of genres on LibraryThing, revealing similarities and differences between them. These measurements are intended to elucidate the genre conceptions of the users, not, as in prior work, to normalize the tags or enforce a hierarchy. We find that LibraryThing users make sense of genre through a variety of values and expectations, many of which fall outside common definitions and understandings of genre.},
journal = {CHI},
month = apr,
NOarticleno = {29},
NOnumpages = {29},
NOkeywords = {book reviews, natural language processing, tagging}
}

@inproceedings{allen2022birds,
author = {Allen, Jennifer and Martel, Cameron and Rand, David G},
title = {Birds of a feather don’t fact-check each other: Partisanship and the evaluation of news in Twitter’s Birdwatch crowdsourced fact-checking program},
year = {2022},
NOisbn = {9781450391573},
NOpublisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502040},
abstract = {There is a great deal of interest in the role that partisanship, and cross-party animosity in particular, plays in interactions on social media. Most prior research, however, must infer users’ judgments of others’ posts from engagement data. Here, we leverage data from Birdwatch, Twitter’s crowdsourced fact-checking pilot program, to directly measure judgments of whether other users’ tweets are misleading, and whether other users’ free-text evaluations of third-party tweets are helpful. For both sets of judgments, we find that contextual features – in particular, the partisanship of the users – are far more predictive of judgments than the content of the tweets and evaluations themselves. Specifically, users are more likely to write negative evaluations of tweets from counter-partisans; and are more likely to rate evaluations from counter-partisans as unhelpful. Our findings provide clear evidence that Birdwatch users preferentially challenge content from those with whom they disagree politically. While not necessarily indicating that Birdwatch is ineffective for identifying misleading content, these results demonstrate the important role that partisanship can play in content evaluation. Platform designers must consider the ramifications of partisanship when implementing crowdsourcing programs.},
booktitle = {Proceedings of CHI 2022},
articleno = {245},
NOnumpages = {19},
NOkeywords = {crowdsourcing, fact-checking, misinformation},
NOlocation = {New Orleans, LA, USA},
NOseries = {CHI '22}
}

@misc{wojcik2022birdwatchcrowdwisdombridging,
      title={{Birdwatch: Crowd Wisdom and Bridging Algorithms Can Inform Understanding and Reduce the Spread of Misinformation}}, 
      author={Stefan Wojcik and Sophie Hilgard and Nick Judd and Delia Mocanu and Stephen Ragain and M. B. Fallin Hunzaker and Keith Coleman and Jay Baxter},
      year={2022},
      eprint={2210.15723},
      archivePrefix={arXiv},
      NOprimaryClass={cs.SI},
      NOurl={https://arxiv.org/abs/2210.15723}, 
}

@article{clarke2025nobody,
  title = {{‘Nobody was tricked into voting for Trump’: Why the disinformation panic is over}},
  url = {https://www.politico.eu/article/nobody-tricked-vote-donald-trump-disinformation-panic-over/},
  journal = {Politico},
  author = {Clarke, Laurie},
  year = {2025},
  month = jan
}

@article{Hoes2024,
  title = {Prominent misinformation interventions reduce misperceptions but increase scepticism},
  volume = {8},
  ISSN = {2397-3374},
  url = {http://dx.doi.org/10.1038/s41562-024-01884-x},
  number = {8},
  journal = {Nature Human Behaviour},
  publisher = {Springer Science and Business Media LLC},
  author = {Hoes,  Emma and Aitken,  Brian and Zhang,  Jingwen and Gackowski,  Tomasz and Wojcieszak,  Magdalena},
  year = {2024},
  month = jun,
  NOpages = {1545–1553}
}

@article{guo-etal-2022-survey,
    title = {{A Survey on Automated Fact-Checking}},
    author = "Guo, Zhijiang  and
      Schlichtkrull, Michael  and
      Vlachos, Andreas",
    editor = "Roark, Brian  and
      Nenkova, Ani",
    journal = "TACL",
    NOvolume = "10",
    year = "2022",
    NOaddress = "Cambridge, MA",
    NOpublisher = "MIT Press",
    url = "https://aclanthology.org/2022.tacl-1.11/",
    NOpages = "178--206",
    abstract = "Fact-checking has become increasingly important due to the speed with which both information and misinformation can spread in the modern media ecosystem. Therefore, researchers have been exploring how fact-checking can be automated, using techniques based on natural language processing, machine learning, knowledge representation, and databases to automatically predict the veracity of claims. In this paper, we survey automated fact-checking stemming from natural language processing, and discuss its connections to related tasks and disciplines. In this process, we present an overview of existing datasets and models, aiming to unify the various definitions given and identify common concepts. Finally, we highlight challenges for future research."
}

@inproceedings{gupta-etal-2021-lesa,
    title = "{LESA}: Linguistic Encapsulation and Semantic Amalgamation Based Generalised Claim Detection from Online Content",
    author = "Gupta, Shreya  and
      Singh, Parantak  and
      Sundriyal, Megha  and
      Akhtar, Md. Shad  and
      Chakraborty, Tanmoy",
    NOeditor = "Merlo, Paola  and
      Tiedemann, Jorg  and
      Tsarfaty, Reut",
    booktitle = "EACL",
    month = apr,
    year = "2021",
    NOaddress = "Online",
    NOpublisher = "ACL",
    url = "https://aclanthology.org/2021.eacl-main.277/",
    NOpages = "3178--3188",
    abstract = "The conceptualization of a claim lies at the core of argument mining. The segregation of claims is complex, owing to the divergence in textual syntax and context across different distributions. Another pressing issue is the unavailability of labeled unstructured text for experimentation. In this paper, we propose LESA, a framework which aims at advancing headfirst into expunging the former issue by assembling a source-independent generalized model that captures syntactic features through part-of-speech and dependency embeddings, as well as contextual features through a fine-tuned language model. We resolve the latter issue by annotating a Twitter dataset which aims at providing a testing ground on a large unstructured dataset. Experimental results show that LESA improves upon the state-of-the-art performance across six benchmark claim datasets by an average of 3 claim-F1 points for in-domain experiments and by 2 claim-F1 points for general-domain experiments. On our dataset too, LESA outperforms existing baselines by 1 claim-F1 point on the in-domain experiments and 2 claim-F1 points on the general-domain experiments. We also release comprehensive data annotation guidelines compiled during the annotation phase (which was missing in the current literature)."
}

@misc{christensen2023promptconditiongenerateclassification,
      title={{Prompt, Condition, and Generate: Classification of Unsupported Claims with In-Context Learning}}, 
      author={Peter Ebert Christensen and Srishti Yadav and Serge Belongie},
      year={2023},
      eprint={2309.10359},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      NOurl={https://arxiv.org/abs/2309.10359}, 
}

@incollection{klein2007data,
  title={A data--frame theory of sensemaking},
  author={Klein, Gary and Phillips, Jennifer K and Rall, Erica L and Peluso, Deborah A},
  booktitle={Expertise out of context},
  NOpages={118--160},
  year={2007},
  publisher={Psychology Press}
}


@inproceedings{card2015media,
  author       = {Dallas Card and
                  Amber E. Boydstun and
                  Justin H. Gross and
                  Philip Resnik and
                  Noah A. Smith},
  title        = {{The Media Frames Corpus: Annotations of Frames Across Issues}},
  NObooktitle    = {Proceedings of the 53rd ACL and the 7th IJCNLP,
                  {ACL} 2015, July 26-31, 2015, Beijing, China, Volume 2: Short Papers},
  NOpages        = {438--444},
  publisher    = {ACL},
  year         = {2015},
  url          = {https://doi.org/10.3115/v1/p15-2072},
  timestamp    = {Sat, 30 Sep 2023 09:33:29 +0200},
  NObiburl       = {https://dblp.org/rec/conf/acl/CardBGRS15.bib},
  NObibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{boydstun2014tracking,
  title={Tracking the development of media frames within and across policy issues},
  author={Boydstun, Amber E and Card, Dallas and Gross, Justin H and Resnik, Philip and Smith, Noah A},
  booktitle={APSA 2014},
  year={2014}
}

@inproceedings{DBLP:conf/emnlp/FieldKWPJT18,
  author       = {Anjalie Field and
                  Doron Kliger and
                  Shuly Wintner and
                  Jennifer Pan and
                  Dan Jurafsky and
                  Yulia Tsvetkov},
  NOeditor       = {Ellen Riloff and
                  David Chiang and
                  Julia Hockenmaier and
                  Jun'ichi Tsujii},
  title        = {Framing and Agenda-Setting in Russian News: a Computational Analysis
                  of Intricate Political Strategies},
  booktitle    = {EMNLP},
  NOpages        = {3570--3580},
  NOpublisher    = {Association for Computational Linguistics},
  year         = {2018},
  url          = {https://doi.org/10.18653/v1/d18-1393},
  NOtimestamp    = {Thu, 14 Oct 2021 09:47:51 +0200},
  NObiburl       = {https://dblp.org/rec/conf/emnlp/FieldKWPJT18.bib},
  NObibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{doi:10.1177/14648849241303249,
author = {Jaume Suau Martínez and Clara Juarez Miro},
title ={Understanding disinformation as narratives in the hybrid media ecosystem: Evidence from the US},

journal = {Journalism},
NOvolume = {0},
NOnumber = {0},
NOpages = {14648849241303249},
NOyear = {0},

URL = { 
    
        https://doi.org/10.1177/14648849241303249
    
    

},
NOeprint = { 
    
        https://doi.org/10.1177/14648849241303249
    
    

}
,
    abstract = { Utilizing data from a representative survey conducted in four U.S. states in mid-2023, the study explores the prevalence and impact of disinformation narratives. It reveals that narratives frequently appear across different media, enhancing their potential to influence public belief significantly when repeatedly exposed. The findings highlight that increased exposure to disinformation narratives intensifies belief in them, with the content of the narratives playing a critical role in their persuasive power. This study contributes to the literature by: i) highlighting the impact of previous exposure to disinformation narratives, ii) emphasizing the importance of narrative frameworks in disinformation research and suggests that understanding the narrative construction of disinformation can lead to more effective and practical fact-checking interventions. It calls for an adjustment in current strategies to accommodate the complexities of media consumption in a hybrid ecosystem, proposing that a focus on narratives could improve the strategic reach and efficacy of interventions like fact-checking. }
}

@article{Knuutila2022,
  title = {{Who is afraid of fake news? Modeling risk perceptions of misinformation in 142 countries}},
  url = {http://dx.doi.org/10.37016/mr-2020-97},
  journal = {Harvard Kennedy School Misinformation Review},
  NOpublisher = {Shorenstein Center for Media,  Politics,  and Public Policy},
  author = {Knuutila,  Aleksi and Neudert,  Lisa-Maria and Howard,  Philip N.},
  year = {2022},
  month = apr 
}

@article{DBLP:journals/corr/abs-2011-00092,
  author       = {Dhruvil Gala and
                  Mohammad Omar Khursheed and
                  Hannah Lerner and
                  Brendan O'Connor and
                  Mohit Iyyer},
  title        = {{Analyzing Gender Bias within Narrative Tropes}},
  journal      = {Arxiv},
  NOvolume       = {abs/2011.00092},
  year         = {2020},
  NOurl          = {https://arxiv.org/abs/2011.00092},
  eprinttype    = {arXiv},
  eprint       = {2011.00092},
  NOtimestamp    = {Fri, 16 Sep 2022 08:16:42 +0200},
  NObiburl       = {https://dblp.org/rec/journals/corr/abs-2011-00092.bib},
  NObibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Devasia2024,
  title = {The role of narrative in misinformation games},
  url = {http://dx.doi.org/10.37016/mr-2020-158},
  journal = {Harvard Kennedy School Misinformation Review},
  publisher = {Shorenstein Center for Media,  Politics,  and Public Policy},
  author = {Devasia,  Nisha and Lee,  Jin Ha},
  year = {2024},
  month = sep 
}

@inbook{Hellman2024,
  title = {Narrative Analysis and Framing Analysis of Disinformation},
  NOISBN = {9783031587474},
  NOISSN = {2945-6126},
  url = {http://dx.doi.org/10.1007/978-3-031-58747-4_4},
  booktitle = {Security,  Disinformation and Harmful Narratives: RT and Sputnik News Coverage about Sweden},
  publisher = {Springer Nature Switzerland},
  author = {Hellman,  Maria},
  year = {2024},
  NOpages = {101–121}
}

@incollection{graham2013moral,
  title={{Moral Foundations Theory: The Pragmatic Validity of Moral Pluralism}},
  author={Graham, Jesse and Haidt, Jonathan and Koleva, Sena and Motyl, Matt and Iyer, Ravi and Wojcik, Sean P and Ditto, Peter H},
  booktitle={Advances in experimental social psychology},
  NOvolume={47},
  NOpages={55--130},
  year={2013},
  publisher={Elsevier}
}

@article{hoover2020moral,
  title={{Moral Foundations Twitter Corpus: A Collection of 35k Tweets Annotated for Moral Sentiment}},
  author={Hoover, Joe and Portillo-Wightman, Gwenyth and Yeh, Leigh and Havaldar, Shreya and Davani, Aida Mostafazadeh and Lin, Ying and Kennedy, Brendan and Atari, Mohammad and Kamel, Zahra and Mendlen, Madelyn and others},
  journal={Social Psychological and Personality Science},
  NOvolume={11},
  NOnumber={8},
  NOpages={1057--1071},
  year={2020},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@article{trager2022moral,
  title={{The Moral Foundations Reddit Corpus}},
  author={Trager, Jackson and Ziabari, Alireza S and Davani, Aida Mostafazadeh and Golazizian, Preni and Karimi-Malekabadi, Farzan and Omrani, Ali and Li, Zhihe and Kennedy, Brendan and Reimer, Nils Karl and Reyes, Melissa and others},
  NOjournal={arXiv preprint arXiv:2208.05545},
  year={2022},
  eprint={2208.05545}
}

@article{10.1093/pubmed/fdae050,
    author = {Lillie, Helen M and Ratcliff, Chelsea L and King, Andy J and Pokharel, Manusheela and Jensen, Jakob D},
    title = {Using narratives to correct politically charged health misinformation and address affective belief echoes},
    journal = {Journal of Public Health},
    NOvolume = {46},
    NOnumber = {3},
    NOpages = {430-436},
    year = {2024},
    month = {04},
    abstract = {In May 2020, news outlets reported misinformation about the Centers for Disease Control (CDC) related to COVID-19. Correcting misinformation about outbreaks and politics is particularly challenging. Affective belief echoes continue to influence audiences even after successful correction. Narrative and emotional flow scholarship suggest that a narrative corrective with a positive ending could reduce belief echoes. Therefore, this study investigated the efficacy of a narrative corrective with a relief ending for correcting misinformation about the CDC.Between 29 May and 4 June 2020, we tested the effectiveness of a narrative to correct this misinformation. Participants in the United States (N=469) were enrolled via Qualtrics panels in an online message experiment and randomized to receive a narrative corrective, a didactic corrective or no corrective.The narrative corrective resulted in lower endorsement of the misinformation compared with the control and the didactic corrective. The narrative corrective had a positive indirect effect on perceived CDC competence and mask wearing intentions for politically moderate and conservative participants via relief.Public health institutions, such as the CDC, should consider utilizing narrative messaging with positive emotion endings to correct misinformation. Narratives better address affective belief echoes, particularly for counter-attitudinal audiences.},
    NOissn = {1741-3842},
    url = {https://doi.org/10.1093/pubmed/fdae050},
    NOeprint = {https://academic.oup.com/jpubhealth/article-pdf/46/3/430/58914952/fdae050.pdf},
}




@inproceedings{sharma-etal-2023-characterizing,
    title = "Characterizing the Entities in Harmful Memes: Who is the Hero, the Villain, the Victim?",
    author = "Sharma, Shivam  and
      Kulkarni, Atharva  and
      Suresh, Tharun  and
      Mathur, Himanshi  and
      Nakov, Preslav  and
      Akhtar, Md. Shad  and
      Chakraborty, Tanmoy",
    NOeditor = "Vlachos, Andreas  and
      Augenstein, Isabelle",
    booktitle = "EACL",
    month = may,
    year = "2023",
    NOaddress = "Dubrovnik, Croatia",
    NOpublisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.eacl-main.157/",
    NOpages = "2149--2163",
    abstract = "Memes can sway people`s opinions over social media as they combine visual and textual information in an easy-to-consume manner. Since memes instantly turn viral, it becomes crucial to infer their intent and potentially associated harmfulness to take timely measures as needed. A common problem associated with meme comprehension lies in detecting the entities referenced and characterizing the role of each of these entities. Here, we aim to understand whether the meme glorifies, vilifies, or victimizes each entity it refers to. To this end, we address the task of role identification of entities in harmful memes, i.e., detecting who is the {\textquoteleft}hero', the {\textquoteleft}villain', and the {\textquoteleft}victim' in the meme, if any. We utilize HVVMemes {--} a memes dataset on US Politics and Covid-19 memes, released recently as part of the CONSTRAINT@ACL-2022 shared-task. It contains memes, entities referenced, and their associated roles: hero, villain, victim, and other. We further design VECTOR (Visual-semantic role dEteCToR), a robust multi-modal framework for the task, which integrates entity-based contextual information in the multi-modal representation and compare it to several standard unimodal (text-only or image-only) or multi-modal (image+text) models. Our experimental results show that our proposed model achieves an improvement of 4{\%} over the best baseline and 1{\%} over the best competing stand-alone submission from the shared-task. Besides divulging an extensive experimental setup with comparative analyses, we finally highlight the challenges encountered in addressing the complex task of semantic role labeling within memes."
}

@inproceedings{DBLP:conf/emnlp/0001ABYBA24,
  author       = {Dustin Wright and
                  Arnav Arora and
                  Nadav Borenstein and
                  Srishti Yadav and
                  Serge J. Belongie and
                  Isabelle Augenstein},
  NOeditor       = {Yaser Al{-}Onaizan and
                  Mohit Bansal and
                  Yun{-}Nung Chen},
  title        = {{LLM Tropes: Revealing Fine-Grained Values and Opinions in Large
                  Language Models}},
  booktitle    = {EMNLP Findings},
  NOpages        = {17085--17112},
  NOpublisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://aclanthology.org/2024.findings-emnlp.995},
  NOtimestamp    = {Mon, 18 Nov 2024 09:06:00 +0100},
  NObiburl       = {https://dblp.org/rec/conf/emnlp/0001ABYBA24.bib},
  NObibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{entman2007framing,
  title={{Framing Bias: Media in the Distribution of Power}},
  author={Entman, Robert M},
  journal={Journal of communication},
  NOvolume={57},
  NOnumber={1},
  NOpages={163--173},
  year={2007},
  publisher={Oxford University Press}
}

@inproceedings{DBLP:conf/eacl/SharmaKSMNAC23,
  author       = {Shivam Sharma and
                  Atharva Kulkarni and
                  Tharun Suresh and
                  Himanshi Mathur and
                  Preslav Nakov and
                  Md. Shad Akhtar and
                  Tanmoy Chakraborty},
  NOeditor       = {Andreas Vlachos and
                  Isabelle Augenstein},
  title        = {Characterizing the Entities in Harmful Memes: Who is the Hero, the
                  Villain, the Victim?},
  booktitle    = {EACL},
  NOpages        = {2141--2155},
  NOpublisher    = {Association for Computational Linguistics},
  year         = {2023},
  url          = {https://doi.org/10.18653/v1/2023.eacl-main.157},
  NOtimestamp    = {Thu, 05 Oct 2023 18:05:02 +0200},
  NObiburl       = {https://dblp.org/rec/conf/eacl/SharmaKSMNAC23.bib},
  NObibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2205-07557,
  author       = {Dominik Stammbach and
                  Maria Antoniak and
                  Elliott Ash},
  title        = {Heroes, Villains, and Victims, and {GPT-3:} Automated Extraction of
                  Character Roles Without Training Data},
  journal      = {Arxiv},
  NOvolume       = {abs/2205.07557},
  year         = {2022},
  NOurl          = {https://doi.org/10.48550/arXiv.2205.07557},
  NOeprinttype    = {arXiv},
  eprint       = {2205.07557},
  NOtimestamp    = {Mon, 05 Feb 2024 20:18:36 +0100},
  NObiburl       = {https://dblp.org/rec/journals/corr/abs-2205-07557.bib},
  NObibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{gidin1980whole,
  title={The whole world is watching},
  author={Gidin, Todd},
  journal={Berkeley: University of CaliforniaPress},
  year={1980}
}

@article{reese2001prologue,
  title={Prologue-Framing public life: A bridging model for media research},
  author={Reese, SD},
  journal={Framing public life: Perspectives on media and our understanding of the social world/Laurence Erlbaum Ass. Publishers},
  year={2001}
}

@article{goffman1974frame,
  title={Frame analysis: An essay on the organization of experience},
  author={Goffman, Erving},
  journal={Northeastern UP},
  year={1974}
}

@article{borenstein2025communitynotesreplaceprofessional,
      title={{Can Community Notes Replace Professional Fact-Checkers?}}, 
      author={Nadav Borenstein and Greta Warren and Desmond Elliott and Isabelle Augenstein},
      year={2025},
  journal      = {Arxiv},
  NOvolume       = {abs/2502.14132},
      eprint={2502.14132},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2502.14132}, 
}

@inproceedings{Warren2025Show,
  author       = {Greta Warren and
                  Irina Shklovski and
                  Isabelle Augenstein},
  title        = {{Show Me the Work: Fact-Checkers' Requirements for Explainable Automated Fact-Checking}},
  booktitle    = {ACM Conference on Human Factors in Computing Systems (CHI 2025), to appear},
  NOpublisher    = {ACM},
  year         = {2025},
  url          = {https://arxiv.org/abs/2502.09083}
}

@article{arora2025frame,
      title={{Multi-Modal Framing Anaysis of News}}, 
      author={Arora, Arnav and Yadav, Srishti and Antoniak, Maria and Belognie, Serge and  Augenstein, Isabelle},
      year={2025},
  journal      = {Arxiv}
}